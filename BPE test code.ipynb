{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text):\n",
    "    words = text.split()\n",
    "    words = [''.join(char for char in word if char.isalnum())  for word in words]\n",
    "    words = [word for word in words if word]\n",
    "    words = [' '.join(list(word)) + ' _' for word in words]\n",
    "    processed_text = ' '.join(words)\n",
    "    return processed_text\n",
    "\n",
    "# print(text_processing(\"The quick brown fox jumps over the lazy dog!!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(text):\n",
    "    vocab_count = defaultdict(int)\n",
    "    processed_text = text_processing(text)\n",
    "    for char in processed_text:\n",
    "        if char != ' ':\n",
    "            vocab_count[char] += 1\n",
    "    return vocab_count\n",
    "\n",
    "# print(get_vocab(\"The quick brown fox jumps over the lazy dog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "{('The', 'quick'): 1, ('quick', 'brown'): 1, ('brown', 'fox'): 1, ('fox', 'jumps'): 1, ('jumps', 'over'): 1, ('over', 'the'): 1, ('the', 'lazy'): 1, ('lazy', 'dog'): 1}\n"
     ]
    }
   ],
   "source": [
    "def get_adjacent_pairs_frequency(processed_text):\n",
    "    chars = processed_text.split()\n",
    "    \n",
    "    pairs_frequency = defaultdict(int)\n",
    "    for i in range(len(chars) - 1):\n",
    "        pair = (chars[i], chars[i + 1])\n",
    "        if pair[0] != '_':\n",
    "            pairs_frequency[pair] += 1\n",
    "    \n",
    "    sorted_pairs = dict(sorted(pairs_frequency.items(), key=lambda x: x[1], reverse=True))\n",
    "    print(len(sorted_pairs))\n",
    "    return sorted_pairs\n",
    "\n",
    "\n",
    "print(get_adjacent_pairs_frequency(\"The quick brown fox jumps over the lazy dog\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_adjacent_pairs_frequency(text):\n",
    "#     processed_text = text_processing(text)\n",
    "#     chars = processed_text.split()\n",
    "    \n",
    "#     pairs_frequency = defaultdict(int)\n",
    "#     for i in range(len(chars) - 1):\n",
    "#         pair = (chars[i], chars[i + 1])\n",
    "#         if pair[0] != \"_\":\n",
    "#             pairs_frequency[pair] += 1\n",
    "    \n",
    "#     return pairs_frequency\n",
    "\n",
    "\n",
    "\n",
    "# print(get_adjacent_pairs_frequency(\"The quick brown fox jumps over the lazy dog\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_vocab(pair, text, vocab):\n",
    "    if not vocab:\n",
    "        vocab = defaultdict(int)\n",
    "    \n",
    "    pair_count = text.count(f\"{pair[0]} {pair[1]}\")\n",
    "    \n",
    "    merged_text = text.replace(f\"{pair[0]} {pair[1]}\", f\"{pair[0]}{pair[1]}\")\n",
    "    \n",
    "    merged_token = f\"{pair[0]}{pair[1]}\"\n",
    "    vocab[merged_token] = pair_count\n",
    "    \n",
    "    for token in merged_text.split():\n",
    "        if token != merged_token:\n",
    "            vocab[token] += 1\n",
    "    \n",
    "    return merged_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "15\n",
      "14\n",
      "14\n",
      "13\n",
      "12\n",
      "13\n",
      "14\n",
      "14\n",
      "low_low_ low_low_ low_ low e s t _ low e s t _ newer_newer_ newer_newer_ newer_newer_ w i d er_ w i d er_ w i d er_ new _ new _\n"
     ]
    }
   ],
   "source": [
    "text = \"low low low low low lowest lowest newer newer newer newer newer newer wider wider wider new new\"\n",
    "\n",
    "\n",
    "def bpe(text, merge_count):\n",
    "    vocab = get_vocab(text)\n",
    "    text = text_processing(text)\n",
    "    \n",
    "    for i in range(merge_count):\n",
    "        pairs_freq = get_adjacent_pairs_frequency(text)\n",
    "        if not pairs_freq:\n",
    "            break\n",
    "        \n",
    "        most_freq_pair = list(pairs_freq.keys())[0]\n",
    "        text = merge_vocab(most_freq_pair, text, vocab)\n",
    "        \n",
    "    print(text)\n",
    "        \n",
    "bpe(text, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
